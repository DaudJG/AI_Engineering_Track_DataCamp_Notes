# Supervised Learning with scikit-learn

## Overview

This folder contains comprehensive notes, exercises, and mathematical breakdowns from the **Supervised Learning with scikit-learn** course, which is part of the AI Engineering track on DataCamp. The course itself covers essential machine learning topics such as classification, regression, model evaluation, and hyperparameter tuning using scikit-learn in Python. I have also extended the content by adding **mathematical explanations** for key concepts to deepen understanding.

## Topics Covered

1. **Classification**
   - Decision Trees
   - K-Nearest Neighbors (KNN)
   - Support Vector Machines (SVM)
   - Random Forests
2. **Regression**
   - Linear Regression
   - Ridge and Lasso Regression
   - Decision Tree Regressors
3. **Model Evaluation**
   - Cross-validation
   - Confusion Matrices
   - ROC Curves and AUC
4. **Hyperparameter Tuning**
   - Grid Search
   - Random Search
   - Cross-validated Grid Search
5. **Pipelines**
   - Building reusable machine learning pipelines
   - Scaling and transforming data within a pipeline

## Learning Outcomes

- **Mastery of scikit-learn:** Acquired in-depth knowledge of supervised learning algorithms and how to implement them using scikit-learn.
- **Mathematical Foundation:** For each concept, I have included detailed mathematical explanations to reinforce the theoretical foundation behind algorithms like Decision Trees, SVMs, Linear Regression, and more.
- **Model Tuning and Evaluation:** Improved skills in evaluating model performance and optimizing hyperparameters to avoid overfitting.
- **Building Pipelines:** Learned how to build efficient and reproducible machine learning pipelines for production-ready workflows.

## Time Commitment

- **Course Duration:** 4 hours
- **Additional Work:** 3 hours of additional work to write detailed notes and document the mathematical theory behind the concepts.
  
Total: **7 hours** dedicated to thoroughly understanding and applying the principles of supervised learning in scikit-learn.

## Notebooks in this Folder

- **01_Classification_with_sklearn.ipynb**  
  Covers classification techniques (Decision Trees, SVMs, KNN, etc.) with code examples and mathematical explanations.

- **02_Regression_with_sklearn.ipynb**  
  Focuses on regression techniques, including mathematical breakdowns of Linear, Ridge, and Lasso Regression.

- **03_Model_Evaluation_and_Selection.ipynb**  
  Includes model evaluation techniques (cross-validation, ROC curves, confusion matrices) and hands-on examples.

- **04_Hyperparameter_Tuning_and_Pipelines.ipynb**  
  Covers hyperparameter tuning techniques and the creation of reusable machine learning pipelines, with theoretical insights.

## How to Use

Each notebook is structured to provide:
- **Concept Explanations:** High-level summaries of each topic.
- **Mathematical Details:** Mathematical derivations and theoretical background for deeper learning.
- **Code Implementation:** Practical examples using Python and scikit-learn.n
- **Exercises:** Hands-on exercises to test your understanding.

Start with the classification and regression notebooks, then progress to model evaluation and hyperparameter tuning.

## Resources Used

- [scikit-learn Documentation](https://scikit-learn.org/stable/)

